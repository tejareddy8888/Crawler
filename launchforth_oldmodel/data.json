{
    "Content": "<div>\n<p>The Human-AV Connect Challenge Handbook can be downloaded <a href=\"https://ucarecdn.com/d1f1c417-78cc-43fe-8415-d5b3ad490e8f/\" target=\"_blank\" rel=\"nofollow noopener\">HERE</a>!</p>\n<p>The Mobility: Moving Life Challenge Handbook can be downloaded\u00a0<a href=\"https://ucarecdn.com/390b5ca3-bb81-4cc0-90cd-7dfb2a31d2df/\" target=\"_blank\" rel=\"nofollow noopener\">HERE</a>!</p>\n</div>",
    "Creation_date": "2019-02-19 23:43:20",
    "Discussion_id": null,
    "Last_Updated_data": "2019-06-14 22:49:58",
    "Project_Title": "AV Tipping Point",
    "Summary": "AV Tipping Point"
}{
    "Content": "<span><strong>Background</strong>\nOriginally this type of pipe, which contains a solid phase butt weld, was produced using resistance heating to make the longitudinal weld via electro-resistance (ERW), but most pipe mills now use high frequency induction heating (HFI) for better control and consistency. These pipe products are still often referred to as ERW pipes, even though the weld may have been produced by the HFI process.\nAfter the ERW or HFI, welding process, used in the manufacture of a pipe, a scarf tool is employed to scrape off both the weld root and weld cap while the metal is still very hot.\u00a0 The objective of the scarfing operation is to ensure the exposed weld area is blended into the diameter of the pipe to the point that it is typically not distinguishable by the naked eye.\u00a0 Pipe of this construction is frequently sold to the Oil and Gas industry and used as well casings and other tubular goods.\u00a0 Industrial standards, like the API 5L document, requires the pipe weld integrity be inspected by ultrasound methods prior to putting pipe into use (in the two different places identified in the image below).\u00a0\nThese inspection methods require close control of the ultrasonic probe to the weld center line (typically within 3mm) to achieve an adequate inspection.\u00a0 Current methods used to control this range from an operator manually moving probes during the inspection to automated methods that follow a scribe or an axial paint line applied to the pipe at the time of manufacturer with a known distance from the weld centerline.\u00a0\nWhen this type of pipe comes out of the welding process the cap and root are peeled off with the goal of matching the ID or OD surface of the pipe.\u00a0 Right after the welder you can see the actual weld line but if the pealed surface isn't uniform on both sides of the weld you don't know where the actual center line is but can assume it's in the center of the pealed area.\u00a0 The problem is compounded further down the line when you inspect a final pipe prior to shipment.\u00a0 The pipe and weld in this case may be a bit rusty, dirty, etc. and it makes it very difficult to visually identify and follow the weld. \u00a0\n<strong>Problem Statement</strong>\nThis project seeks to develop a non-destructive method to identify and monitor the weld seam centerline in ERW/HFI welded pipe during pipe manufacturing after the SCARF process.\u00a0 The desired solution will allow for accurately following a weld seam during ultrasonic inspection, greatly improving the inspection integrity of critical oil and gas assets.</span>",
    "Creation_date": "2016-10-18 03:41:10",
    "Discussion_id": 62826,
    "Last_Updated_data": "2018-03-29 19:30:07",
    "Project_Title": "Detecting Weld Seams",
    "Summary": "Detecting Weld Seams"
}{
    "Content": "<div><p>Local Motors has become psyched about the opportunity and buzz around the Internet of Everything movement, and we are interested to see where this adventure can take us. To that end, we recently joined the AllSeen Alliance by the Linux Foundation to get a front row seat to the internet of things incorporation into the world.\nThis open source connected Rally Fighter includes:\n</p><ul>\n<li>Linux powered with Automotive Grade Linux <a href=\"http://www.tizenassociation.org/\">www.tizenassociation.org</a> <a href=\"http://automotive.linuxfoundation.org/\">automotive.linuxfoundation.org</a></li><li>Raspberry Pi\u00a0board wired into the control harness via Arduino relay boards</li><li><a href=\"http://octoblu.com\">Octoblu's</a> open source\u00a0<a href=\"http://meshblu.octoblu.com\">Meshblu\u00a0</a>private IoT\u00a0cloud,\u00a0<a href=\"https://github.com/octoblu/gateblu\">Gateblu\u00a0</a>IoT gateway,\u00a0and\u00a0<a href=\"https://github.com/octoblu/microblu_mqtt\">Microblu\u00a0</a>Arduino IoT\u00a0operating system</li><li>Octoblu's\u00a0<a href=\"https://chrome.google.com/webstore/detail/nodeblu/aanmmiaepnlibdlobmbhmfemjioahilm\">Nodeblu\u00a0</a>Chrome app for controlling Internet of Things connected devices</li></ul>\n<strong>Challenges: </strong>We have control via Nodeblu and other IoT protocols (HTTP, WebSockets,\u00a0MQTT, CoAP, and AllJoyn) of the Hazard lights, headlights, door locks, and windshield wipers. We can also mesh other private and public\u00a0Octoblu clouds together forming a rolling mesh network.What cool demos should we do at the for upcoming events to mimic real world needs or show off the capabilities of open source IoT and Cloud in things that roll?How could we implement this cool open source technology into our projects here at Local Motors?\u00a0\nSee the discussion page and collaboration requests below to help us brainstorm!</div>",
    "Creation_date": "2014-04-05 02:00:00",
    "Discussion_id": 62843,
    "Last_Updated_data": "2018-01-31 23:17:21",
    "Project_Title": "Connected Car Project (Internet of Things)",
    "Summary": "Connected Car Project (Internet of Things)"
}{
    "Content": "<p>In the age of smartphone apps and bitcoins, we make purchases using our phones, watches, or even our home speakers, which is convenient, but has its downsides. As spending has gotten easier our physical connection to the currency has diminished resulting in a mental disconnect between what we are buying and how much we are spending. As a result, many people, adults and younger people alike, have a difficult time truly understanding their spending and can lead to some very sticky financial situations.\nAccording to the <a href=\"http://www.apa.org/pubs/journals/releases/xap143213.pdf\">American Psychological Association</a>, physically handling money triggers what is referred to as the \u201cpain of paying\u201d response, which sounds bad, but it helps with responsible spending by maintaining contextual awareness to your account balance.\u00a0\nFor example, if you are buying a pack of gum at the store, and you pull $5 out of your pocket. You can easily watch as 20% of your available funds are chewed up. This experience immediately informs the next purchase that you make. By watching your finances diminish, you are aware of your available balance as well as making you question the personal value that you receive from your next purchase.\nOn the other side, if you have $5 in an online account and pay with a debit card, you can still make the purchase, but for something small like gum, the purchase feels less significant and the tendency to ignore the effect of that purchase is increased, causing you to forget that you made the purchase or\u00a0 to minimize how much it actually cost.\u00a0\u00a0\nOur goal for this project is to help recreate this \u201cpain of spending\u201d feeling by creating a physical object where a user can not only see, but also physically interact with their spending beyond the digital screen in positive, educational, and engaging interaction.\n<strong>Additional Insights:</strong> \n<a href=\"https://www.dailyworth.com/posts/how-do-we-teach-kids-about-money-when-they-never-see-cash\">How Do We Teach Kids About Money when the never see cash?</a>\n<a href=\"http://www.apa.org/pubs/journals/releases/xap143213.pdf\">Monopoly Money: The Effect of Payment Coupling and Form on Spending Behavior</a>\n<a href=\"http://www.cnbc.com/video/2014/12/10/kids-families-the-cashless-society.html\">Kids, Families, and the Cashless Society</a></p>",
    "Creation_date": "2017-10-10 23:27:38",
    "Discussion_id": null,
    "Last_Updated_data": "2017-12-12 17:32:22",
    "Project_Title": "IoT Wallet",
    "Summary": "IoT Wallet"
}{
    "Content": "<p>Problem Statement\n  \nFrom food processing plants to agriculture to petroleum refineries, high temperature pipes and equipment are often covered in insulation to prevent heat loss and to protect plant employees. If water gets between the insulation and the piping, corrosion can occur, leading to leaking of process liquid or vapors \u2013 a major safety concern. We are looking for a mechanism for monitoring corrosion under insulation. \u00a0\n  \nFrequently Asked Questions (FAQs)\n  \n<strong>Q: What are the indicators of corrosion?</strong>\n  \nCorrosion under insulation (CUI) occurs in the presence of water, oxygen and proper temperature. Corrosion can affect the pipe or equipment being insulated, the insulation and/or the protective material covering the insulation called the jacketing. Because of this, the indicators can be material, chemical and/or physical. \n  \nFor pipes made of carbon and low alloy steel, the temperature range for corrosion is wide, between 10 and 250 degrees F. With this large range, the threat of moisture from condensation, leaks in insulation, rain, and fire protection systems, the risk of CUI is high but difficult to pinpoint. With hundreds of miles of insulated piping and equipment per processing plant, a more thorough mechanism is needed to identify corrosion. \n  \n<strong>Q: Are there different types of corrosion?</strong>\n  \nYes. The most common types of corrosion are galvanic, chloride, acidic, or alkaline corrosion.\n  \n<strong>Q: What are current ways to identify corrosion?</strong>\n  \nThe most obvious way to identify corrosion is the removal of the insulation to look at the equipment. This can be time consuming, expensive, and could add additional risk of future moisture seeping in from the removal/reinstall process. \n  \nNon-destructive testing (NDT) processes currently used to identify corrosion include radiography, pulsed eddy current (PEC), guided-wave ultrasonics, ultrasonic thickness measurements. Other tools attempt to identify moisture under insulation, although there are cases where corrosion may not be occurring, or dry areas where corrosion has already occurred.</p>",
    "Creation_date": "2017-03-15 10:00:01",
    "Discussion_id": null,
    "Last_Updated_data": "2018-03-29 18:16:17",
    "Project_Title": "Detecting Corrosion Under Insulation",
    "Summary": "Detecting Corrosion Under Insulation"
}{
    "Content": "<p>Join the UM:SmartCart team, lead by Ed Olsen \u2014 director of University of Michigan\u2019s APRIL Robotics Lab \u2014 and help create the first generation of 3D-printed low-speed autonomous vehicles. You can help members of the team by providing suggestions and insight for physical modifications to the vehicles such as mounting sensors, computers, and antennas.</p>",
    "Creation_date": "2015-09-10 21:00:26",
    "Discussion_id": 62801,
    "Last_Updated_data": "2017-12-12 17:45:33",
    "Project_Title": "UM SmartCart",
    "Summary": "UM SmartCart"
}{
    "Content": "<span><strong>Background</strong>\nBorescopes, an instrument used to inspect the inside of a structure through a small hole, are the current technology used to inspect things like the inside of LEAP jet engines to check for . While the engine might have to be checked frequently for safety, it can't be taken apart each time, so small tools, like the borescope, to complete inspections. Here is a sample video of a borescope inspection on a less shiny turbine:\n<iframe src=\"//www.youtube.com/embed/CykduKWAU6w\"></iframe>\n<strong>Problem Statement</strong>\nAll across the world, operators are looking inside big machines that are either too time intensive or can\u2019t be taken apart, such as LEAP jet engines. Sometimes, inspections of engines delay flight times because the shiny polished surfaces of jet engines, that are traditionally inspected with borescopes, reflect light so well that they defy measurements of indications or defects with visible light. So, how do we inspect these places more accurately and efficiently? Reflect on this, your future flight time could depend on it.</span>",
    "Creation_date": "2016-10-18 03:41:03",
    "Discussion_id": 62834,
    "Last_Updated_data": "2018-03-29 22:06:21",
    "Project_Title": "Measuring Reflective Objects",
    "Summary": "Measuring Reflective Objects"
}{
    "Content": "<div><p>Background Local Motors has created Olli, a self-driving electric shuttle connecting public transit riders, moving people around campuses, and eventually moving people in upcoming car-free downtown zones. It carries 12 people effortlessly and sustainably at 25 mph to local destinations and was the winning entry of Edgar Sarmiento\u2019s (@eddie_mauro) in LM Labs\u2019 international Urban Mobility Challenge. #AccessibleOlli seeks to offers mobility, independence and freedom to the growing aging community as well as those with impairments. The leading ideas for this project will result in a prototype #AccessibleOlli show vehicle that will be built and shown at CES 2018 in Las Vegas. The ideas generated will also inform the production of future Olli vehicles. <strong><a href=\"https://www.youtube.com/watch?v=XQU6bGVRRWE\">#AccessibleOlli Introduction Video (3 min)</a></strong> Objectives Given the expanding demographic of the aging public, along with new opportunities to apply powerful new IoT technologies to help those with impairments #AccessibleOlli will:</p>\r\n<ul>\r\n<li>Allow older adults to age in place and remain independent and self sufficient within their communities</li>\r\n<li>Assist those with vision, hearing, cognitive or physical mobility impairments to leverage transportation, improving their independence and quality of life</li>\r\n<li>Provide enhanced access to work opportunities and community services to people of all ages and abilities</li>\r\n<li>Ensure a successful transition to driverless vehicles for all.</li>\r\n</ul>\r\n<p>While we understand that each riders needs are unique to them, we are focusing on the following to the four (4) tracks.</p>\r\n<ul>\r\n<li>Mobility impairment, e.g. wheelchair, walker</li>\r\n<li>Vision impairment, e.g. blind</li>\r\n<li>Hearing impairment, e.g. deaf or hard of hearing</li>\r\n<li>Cognitive impairment, e.g. memory deficiency</li>\r\n</ul>\r\n<p>To meet the needs of aging and disabled populations, technology and AI will need new User Interfaces (UIs) that are completely redesigned to meet unique interaction requirements. \u00a0Conventional vehicle UI will give way to access methods for people with less dexterous mobility, poorer hearing, lower vision and a variety of cognitive impairments. \u00a0Voice commands and touchable interfaces will be required; new AIs will need new UIs. And we need personalization of every user experience, adapting the vehicle/occupant interaction to include language used, physical environment, and preferences with regards to modality of interaction - speech, text, touch (haptic). IBM is showing the world the possibilities for new IoT solutions, allowing us to dream about the #AccessibleOlli and the future shuttle that everyone will be able to enjoy. This project is not about meeting a minimum of accessibility design. The Consumer Technology Association (CTA) Foundation, IBM, and other companies are contributing to this project. Frequently Asked Questions: <strong>Q: What is the intention of the #AccessibleOlli Challenge?</strong>To design Olli to accommodate all riders, even those with disabilities. The challenge brings together product designers, vehicle designers, engineers, technologists, fabricators, design for disability experts, and many other participating disciplines to create a meaningful #AccessibleOlli design. <strong>Q: Why focus on aging?</strong>Today\u2019s world populations are living longer and we need to address that fact in our new transportation systems. The United Nations estimates that by 2030 there will be a 56% increase in the number of people older than 60, and by 2050, the \u2018over 80\u2019 population will have nearly tripled. <strong>Q: Why focus on disabilities?</strong> Our mobility vehicles should accommodate any rider. In the past, it was difficult to address all rider\u2019s needs that have impairments. Today with the power of IBM\u2019s IoT technologies, there are many new solutions to be explored. <strong>Q: Will accessibility design help all users?</strong> It is possible the breakthrough new technologies available to rethink shuttle mobility for riders with disabilities could also result in new mobility UX solutions that make travel nicer for everyone. <strong>Q: Is this really about ADA?</strong> Americans with Disabilities Act of 1990 enables riders with certain disabilities a means to use public transit. The ADA requirements for a self-driving shuttle have yet to be defined. #AccessibleOlli is seeks to make the Olli autonomous[1] \u00a0shuttle functional for as many people as possible. <strong>Q: Is there any autonomous[2] \u00a0ADA compliant vehicle today?</strong> We don\u2019t know of one. We should also mention that every public transit vehicle on the streets of the US has a human operator, that often assists in wheelchair loading and securement. <strong>Q: Olli is a local shuttle. How does that impact accessibility design?</strong> Most passengers will ride Olli for relatively short trips and will seek quick loading (and un-loading) for all, or they may prefer to walk? <strong>Q: What is Olli occupancy?</strong> Olli\u2019s current design calls for 8 people seated and 4 standing. That layout could change based on the #AccessibleOlli Challenge design results. <strong>Q: What is the role of IBM Watson technology?</strong> IBM Watson offers AI capabilities including machine vision, natural language processing and the ability to \u2018learn\u2019 user preferences. \u00a0This creates unique opportunities for engaging humans to make them feel comfortable, personalizing human experiences, addressing their challenges, and earning human trust (which supports and coincides with trust-building happening between humans and autonomous vehicles, naturally and over time). IBM Watson technology imbedded in Olli, provides personalization opportunities that can be tailored for each unique user\u2019s experience <strong>Q: How can Olli accommodate a rider in a wheelchair?</strong> Local Motors is seeking solutions from the #AccessibleOlli Challenge as to how a passenger in a wheelchair is accommodated on Olli. There is a wide range of needs for Olli to carry a passenger in a wheelchair, from the wheelchair rider arranging for the trip, to boarding, being secured in an automated manner, to exiting and so on. When someone in a wheelchair approaches Olli, a ramp will need to be activated or another approach to boarding the rider. Once inside, Olli could activate a seat to fold up for securing the wheelchair. <strong>Q: How can Olli help a rider that is blind or has difficulty seeing?</strong> Olli seeks to leverage IoT technology to help those with visual impairment move freely. This rider may need help arranging a ride, navigating to Olli, navigating onto Olli, securing a seat / location on the vehicle, be alerted when time to exit Olli, and exiting Olli at their destination. they also are able to know they are going to exactly the right place - and they can use voice control to route there, giving them confidence to travel and explore. <strong>Q: How can Olli help a rider that is deaf or has trouble hearing?</strong> The #AccessibleOlli co-creation project seeks solutions that apply the latest IoT technologies so those passengers with hearing impairments can easily use the Olli shuttle. \u00a0Olli needs to have more signage, more visual info and cues (inside and outside) than public transit currently offers. <strong>Q: What other approaches work for people with hearing impairments?</strong> Someone that communicates via sign language may board #AccessibleOlli, use sign language to communicate \u201cTake me to the library\u201d, and #AccessibleOlli may have an avatar / hologram / screen that actually responds back in sign language. <strong>Q: Since there is no human operator on Olli, does that make IoT technology more important?</strong> Yes, If there is no bus driver, then who welcomes you aboard? Who do you talk to? Who tells you what to do? Who answers your questions and addresses your concerns? \u00a0Who tells you where you\u2019re going and when you\u2019re arriving? These are all considerations for a small self-driving transit vehicle.</p></div>",
    "Creation_date": "2017-04-17 22:14:46",
    "Discussion_id": null,
    "Last_Updated_data": "2017-12-12 17:39:46",
    "Project_Title": "#AccessibleOlli",
    "Summary": "#AccessibleOlli"
}{
    "Content": "<span><strong>Background</strong>\nHistorically, X-rays used only film which caused cumbersome and lengthy processing times. Digital X-rays were made possible by radiography scanners that scan the X-ray image and captures it as a digital one. These field radiography scanners use plates (similar to film in film cameras) on which X-rays are taken. The plates are then scanned to digitize the X-rays. Since these plates contain an imaging phosphorous layer, they are (rather unimaginatively) called imaging phosphorous plates, or IP plates for short. GE\u2019s field radiography\u00a0scanners, used for\u00a0weld inspection and other areas of non-destructive testing, can only use IP plates made specifically for them. We are looking for ways to create a universal adapter that can fit all \u201cmakes and models\u201d of IP plates so that buying our plates isn't required.\n<strong>Meet your SMEs</strong>\n\nSteven, @stevenwissels, is a Global Product Sales manager for Field Radiography.     Previously, he\u00a0was also\u00a0the Product Manager for CR (Computed Radiography). He has\u00a015+ years of experience in Digital Radiography, working for AGFA and later on for GE Inspection Technologies.     Both of us are employed in the Centre of Excellence for Digital Radiography, based in Belgium.\nJohan, @johangrauls, is a sales application engineer with over 20 years of experience in field radiography applications both digital and conventional, supporting the sales organisation world wide and leading the Centre of Excellence\u00a0(application center for digital conversion) in Belgium.\n<strong>Frequently Asked Questions</strong>\n<strong>Question: What is computed radiography?</strong>Computed radiography (CR) is technology that records radiographic images on photosensitive phosphor imaging plates (IP) instead of traditional industrial film. After exposing the test object positioned between the X-Ray source and the IP the imaging plate is then scanned in a CR scanner.\n<strong>Q. Why is CR used?</strong>Computed Radiography is used in the industry to inspect objects (such as blades, welds, pipes) without having to damage or open the object. This technology is using reusable IP plates, resulting in lower inspection costs, and at the same time having shorter exposure times than with industrial film.\n<strong>Q: Why is the system important to the industry?</strong>The system is today\u2019s leader in for computed radiography scanners. It is one of the few, if not the only system able to meet the stringent ISO Standard (for inspection of welds), and achieve requisite resolution demands with short exposures and high throughput.\n<strong>Q: Why this challenge?</strong>The system was designed to work with IP plates specifically made for it. These are GE\u2019s custom made IP plates. The time is ripe for the scanner to be democratized to be usable with any IP plate. This would let all customers take advantage of it without having to buy GE\u2019s custom made IP plates and open the possibilities of the scanner to a much wider range of users.\n<strong>Q: Why not simply use the same system as other scanners?</strong>Standard transport systems, for taking IP plates through the scanner, involved the use of foam rollers on both sides. This resulted in the active phosphor layer being touched by the rollers. To have extreme high resolution images,\u00a0it is necessary to avoid touching the active front phosphor layer. This resulted in the scanner having to use specially designed IP plates that are carried using a magnetic backing, which removes the need for rollers on the sides.\n<strong>Q: How are the plates currently transported through the scanner?</strong>The backside of the IP (being ferromagnetic) is picked up by a magnetic roller to start the transport process. Lateron, a magnetic belt is used to obtain a steady high quality transport.\n<strong>Q: Can pressure be applied as a holding mechanism and if yes, where?</strong>Yes, pressure could possibly be used. However, the active area of the plate should not receive any pressure from the holder \u2013 and should not be obscured by the holding mechanism from the scanner.\n<strong>Q: How would a transport system for the plates affect the quality of scan images?</strong>The back side of the plates can potentially scatter X-rays. Thus, if a non-uniform solution is used on the back of the Imaging plates that also scatters X-rays, then the image might contain artifacts which can interfere with the interpretability of the scan images.\n<strong>Q: What is the current throughput of the scanner?</strong>45 plates (14\u2019\u2019 x 17\u2019\u2019) per hour @ 70micrometer resolution and 16 per hour at 35 micrometer\n<strong>Q: What are the maximum/minimum outer dimensions of the adapter plate?</strong>\u00a0The maximum width of an IP is 14 inch (35cm). The longest plate we currently provide is 1.5m (with a width of 10cm)\n<strong>Q: How does the plate currently move through the scanner? Can you explain the ferromagnetic backing?\u00a0</strong>The IP has a ferromagnetic back layer which is being picked up by a magnetic roller at the entrance of the scanner, just behind the feeding / input table. The roller transports the IP onto the transportation belt. The IP is fed with the phosphor side up and the back layer down.\n<strong>Q: Are the magnetic rollers located on the bottom?</strong>\u00a0Yes.\n<strong>Q: How strong/sensitive is the magnet?</strong>\u00a0The magnetic roller is just strong enough to pick up the IP. Longer plates need some help to be transported.\n<strong>Q: If the transport mechanism doesn\u2019t touch the imaging surface, so does it float with the magnetic rollers?\u00a0</strong>The storage phosphor side is upwards and doesn\u2019t come in contact with anything. After making an exposure with x \u2013 or gamma ray, the energy is absorbed by the phosphor. When the IP goes through the scanner it is being attacked by the red laser. Blue light comes out of the IP and is being picked up by a light guide which transports the light into the PMT (photo multiplier) which is your AD converter.\n<strong>Q: How sensitive are the plates? Are adhesives an instant problem?</strong>\u00a0Adhesive might leave residue on the back side of the IP. The plate just has to stay in position during transport (on a layer?). Plate should come of easy after scanning.\n<strong>Q: The goal to search a new adapter is only to improve the quality of the images?</strong>\u00a0No, the goal is to provide a solution for scanning longer IP\u2019s and odd shapes\n<strong>Q: Modifications to the CRxVision equipment can be proposed?\u00a0</strong>Depends on cost, but we suggest not making modification.\n<strong>Q: In the case of designing a \u201cholder\u201d for competitor plates: could any pressure be applied to the top of the IP plate? If yes, which area (and how much of it) could be used for \u201cclamping\u201d or \u201cholding?\u201d</strong>\u00a0Yes, could be possible, but take care that the IP plate is storing the actual image to be scanned. Typically the important part of the weld is in the middle of these long plates, be we have applications (not that much, I would estimate less than 5% ) where customer is looking for indications up to the side of the IP.\n<figure><img src=\"https://ucarecdn.com/d4bc49ba-7802-4cea-8a18-074227ee1772/-/preview/1440x1080/\"></figure>\n<strong>Q: Are the IP plates fed in sets or could the process be continuous?</strong>\u00a0Both, but typically they will be fed like in the pic above. 2 up to 4 plates to be scanned, then images are pre-evaluated, and next IP inserted to be scanned.On average how many IP plates are processed by the operator/ technician?\u00a0This highly depends on the application (weld inspection or full production). I would say customers prefer almost continuous throughput (see datasheet for numbers).\n<strong>Q: Would different materials, placed on the back/bottom side, affect the performance of the scanner? If so, what material would not be recommended for recommended design?</strong>\u00a0Recommended: homogeneous\u00a0uniform products, Teflon, plastics. Not recommended: non-uniform structured materials visual with radiography.What would happen if someone tried to feed competitors IP plate into the machine? Would the IP plate(s) move at all?\u00a0IP would not move at all as only backside magnetic roll is available, and it would not pick up the IP at all.</span>",
    "Creation_date": "2017-01-25 15:38:17",
    "Discussion_id": 62778,
    "Last_Updated_data": "2018-03-29 18:49:59",
    "Project_Title": "Universal X-ray Plate Adapter",
    "Summary": "Universal X-ray Plate Adapter"
}{
    "Content": "<span><strong>Background</strong>\nCT, computerized tomography, technology is widely used to inspect objects during manufacturing processes in many industries to ensure they meet desired specs. In many cases, thousands of large scans, up to 80 GB, generated daily need to be analyzed by offsite inspectors. The transfer of these large scans can take days, creating bottlenecks in the overall manufacturing process.\nCheck out the video below to learn more about GE Inspection Technology CT technology and manufacturing plant:\n<iframe src=\"//www.youtube.com/embed/dbY7D5BE-U0\"></iframe></span>",
    "Creation_date": "2016-10-18 03:41:16",
    "Discussion_id": 62784,
    "Last_Updated_data": "2018-03-29 19:24:43",
    "Project_Title": "Speedy CT Image Delivery",
    "Summary": "Speedy CT Image Delivery"
}{
    "Content": "<div><p>Position sensors are ubiquitous in today\u2019s world \u2013 though they are often known by other names. If you have ever used a computer mouse, you have used a position sensor. This project explores coupling a low cost wireless position sensor with hand-held ultrasonic testing (UT) inspection units to make inspections faster, more accurate and safer.\nPosition sensors are ubiquitous in today\u2019s world \u2013 though they are often known by other names. If you have ever used a computer mouse, you have used a position sensor. One of the most complex position encoders would be a variety of technologies that utilize GPS. Considering we are able to detect the position of your car to a few meters with the points of reference being in, quite literally, outer space \u2013 it is quite a technological feat. Somewhere in the middle of the spectrum lie sensors such as <a href=\"https://www.ascension-tech.com/products/\">flock of birds</a> or <a href=\"https://www.youtube.com/watch?v=BG80pCf25BE\">trakStar</a>. As you can see, position sensors can we wired or wireless, affordable or very expensive.\u00a0 \n  \nThis challenge seeks to couple a low cost wireless position sensor with hand-held ultrasonic testing (UT) inspection units to make inspections faster, more accurate and safer. \n  \nUT is an extremely common non-destructive testing process that is widely used in many industries. Industrial applications range from measurement of wall thickness in oil &amp; gas pipe lines (to evaluate corrosion damage) to the measurement of defects in composite parts of wind turbines to microstructure evaluations of welds during pipe manufacturing.\u00a0 \n  \nWhile there have been several automation products for taking UT measurements, such as crawlers, robots and pigs \u2013 there is still a large need for manual inspections. There are several inspection scenarios where the use of a robotic crawler is not practical. Consider for example, a complex bend in a pipe that is suspended several feet above the ground in a refinery as part of a large piping network. A robotic crawler wouldn\u2019t be able to carry the weight of the cables or the couplant lines and the clearance available around the pipe is often too small to accommodate it. Portable UT systems largely solve these issues with a system that is small enough to be carried to the asset by an operator. \n  \n<img alt=\"probe.jpg\" src=\"https://ucarecdn.com/d16f63f6-37de-4f22-a243-0f0932076d0d/-/preview/1024x2048/\">However, with the increase in popularity of handheld units that allowed for easy scanning, also arrived a new complication. These units don\u2019t provide a way to accurately track the position of the sensor on the scan surface. Therefore, if the operator wanted to pinpoint the location of an indication he saw on the scan or screen, there is no real way to do it. For example, in the image below, showing the ultrasound scan image of a flat plate, it is easy to see that there are multiple defects within the scan area, seen as red spots. However, if one of those red spots are identified as a defect for further investigation, there is no way to correlate that spot to an exact location on the pipe \u2013 most operators today try to mark the approximate point with something physical such as a sharpie for further future investigation.\u00a0\n<img alt=\"Scanner display.jpg\" src=\"https://ucarecdn.com/cc80f67c-1aa2-4187-9150-cc656efa2608/-/preview/1024x2048/\">There are two ways this problem is addressed in the field. One is to pre-grid the areas to be scanned. For example, if an operator is inspecting a pipe elbow in a refinery, she/he manually draws a grid of say 1cm x 1cm on this pipe with a marker or something and inspects in each \"square\" of the grid. This, however, is too time consuming and error-prone. For very hard to reach and complex shaped structures (imagine a complex bend in a pipe that passes over and under multiple other pipes carrying very hot liquid in a refinery), it often takes several hours just to grid the pipe section \u2013 and that is prior to even beginning the scan.\n\n The second option is to use an encoder attachment on the transducer as in the video:\n<iframe height=\"315\" src=\"https://www.youtube.com/embed/e2bblOJKoGY\" width=\"560\"></iframe>\n\u00a0\u00a0For this method, the encoder results in a system that is inherently limited in the scan \u201cfreedom\u201d \u2013 the scans must conform to a surface, must be along a line etc. The system is also bulky and unwieldly with wires, couplant line, encoder data etc., all of which must be carried along with the transducer.\nWith the community\u2019s help, we want to develop a wireless position encoder that makes the job of the inspector easier and safer by eliminating the hours needed for gridding an asset before scanning it in a fundamentally hazardous environment. Even more, a position sensor would enable much higher scan resolution than what could be obtained by even the most painstakingly created manual grid.\u00a0 This enhanced resolution will directly translate into early detection of issues and increased safety of the assets being inspected. \n  \nWhile the ideal submission will be applicable to a wide variety of ultrasonic inspections, the minimum requirement for this challenge is the design of a wireless position sensor for the manual ultrasonic inspection of pipe welds.\n\nFAQs\n</p><ul><li>How many degrees of freedom are required for tracking? \n  <ul><li>We would need to measure 3D position (so X, Y, Z) and the angle of rotation in the plane of the sensor-- we would need to allow for all 6DOF of motion but we only need to measure only the 4 \u201ccoordinates\u201d. \n  </li></ul></li><li>What is the envelope for the measurement ? \n  <ul><li>We are hoping to measure a curved surface (like a pipe surface) that can be projected on to a 1m x 1m square (one would topologically call this a manifold but basically we are looking for a 2.5 D surface, that is a surface that is curved in 3 dimensions).\u00a0 We would like a resolution of 1mm or less in each of the three dimensions.\n  </li></ul></li><li>How often the position data needs to be refreshed, i.e. Bandwidth?\n  <ul><li>Refresh rates of 50Hz or higher are necessary. The higher the better. \n  </li></ul></li><li>Can the tracking device be placed onboard the item? or is the tracked item expected to be in its own configuration (no additional components installed)\n  <ul><li>Yes the actual tracker should be placed on board the inspection probe.\n  </li></ul></li><li>What position sensing technologies could be used ? \n  <ul><li>Anything that doesn\u2019t conflict with the ultrasound testing system could potentially be used. Do be aware that the pipes may be ferromagnetic. \n  </li></ul></li><li>What is the frequency range of the UT inspections being carried out today ?\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \n  <ul><li>500Hz \u2013 15KHz. \n  </li></ul></li><li>How are manual inspections done today ? \n  <ul><li>Currently manual inspections are done by \"gridding\" an area \u2013 if we go back to our pipe inspection, the operator manually draws a grid of say 1mm x 1mm on this pipe with a marker or something and inspects in each \"square\" of the grid.\n  </li></ul></li><li>Can you describe a typical use case ? \n  <ul><li>A pipe with a diameter of around 12inches (can range from 1 to 36 inches), with a bend radius of 2.0 D (D - diameter of the pipe), suspended 50ft above the ground with a clearance of 1ft on all four sides. 1ft is the minimum distance between the OD of the pipe and the outer surface of the nearest structure.\u00a0\u00a0\u00a0</li></ul></li></ul></div>",
    "Creation_date": "2017-05-09 16:04:11",
    "Discussion_id": null,
    "Last_Updated_data": "2018-03-29 18:14:29",
    "Project_Title": "Position Sensor for Inspection Probes",
    "Summary": "Position Sensor for Inspection Probes"
}{
    "Content": "<span><strong>Problem Statement</strong>\nAirplane operators have time constraints to complete the inspections to return the airplane to service. The process of borescope inspection is time consuming as the inspector evaluates each component after waiting for the engine to cool sufficiently from the previous flight. \u00a0Most of the time, the inspector does not record imagery of the inspected parts. \u00a0Even when photographs, or videos, are recorded, there is variation of the hardware view because the probe is manually positioned. This variation makes auto interpretation of the imagery almost impractical. \u00a0Advances in imaging technologies present an opportunity to disrupt the old technology to allow capture of consistent, high quality digital imagery at less costs and burden to the operator. Likewise, advances in data management and automated image analysis enable advanced processing and analytics of inspection results.\n<strong>Background</strong>\nGas turbine parts requiring the most careful attention are those associated with the combustion process, together with those exposed to the hot gases discharged from the combustion system. These are called the combustion section and hot gas path parts, and they include combustion liners,\u00a0fuel nozzle assemblies,\u00a0turbine nozzles, turbine stationary shrouds, and turbine blades.\nGas turbine aircraft engines require periodic inspections of critical internal parts to verify serviceability for continued operation. These inspections are normally focused on the high pressure hot gas path hardware (combustion chamber, high pressure turbine \u2013HP- rotor blades and stationary vanes and shrouds). These inspections are done by borescopes using a manually controlled probe. This basic technique was developed over 70 years ago.\nAll jet engines are designed with access ports that enable a borescope to be inserted into the engine at each location within proximity of the parts to be inspected. A certified inspector inserts a borescope probe into the selected access port and manually manipulates the borescope camera, or fiber optics viewing window, to assess the internal part condition against serviceability limits provided by applicable maintenance manuals.</span>",
    "Creation_date": "2016-10-13 20:43:45",
    "Discussion_id": 62802,
    "Last_Updated_data": "2018-03-29 22:08:56",
    "Project_Title": "On-Wing Engine Inspection",
    "Summary": "On-Wing Engine Inspection"
}{
    "Content": "<div><p>Take a look at the following documents that further describe Olli:</p>\r\n<ul>\r\n<li><a href=\"https://drive.google.com/file/d/0B2FExbrcnt08anJYUFBRY1NWMzA/view?usp=sharing\">Olli Specification Sheet (Rev 12-22)</a></li>\r\n</ul></div>",
    "Creation_date": "2016-06-20 15:52:41",
    "Discussion_id": 62812,
    "Last_Updated_data": "2017-12-12 17:35:12",
    "Project_Title": "Olli: self-driving, cognitive electric shuttle",
    "Summary": "Olli: self-driving, cognitive electric shuttle"
}